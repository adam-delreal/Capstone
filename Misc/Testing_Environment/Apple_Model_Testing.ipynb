{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling - Apple, Inc. (AAPL)\n",
    "\n",
    "## Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Company Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = 'Apple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(company_name):\n",
    "    company_name=company_name\n",
    "    df = pd.read_csv(f'data/{company_name}_Clean.csv')\n",
    "    df['Date'] = pd.to_datetime(df.Date)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df.sort_index(inplace=True, ascending=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_reader('Apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex_Dividend</th>\n",
       "      <th>Split_Ratio</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Adj_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>28.75</td>\n",
       "      <td>28.87</td>\n",
       "      <td>28.75</td>\n",
       "      <td>28.75</td>\n",
       "      <td>2093900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.422706</td>\n",
       "      <td>0.424470</td>\n",
       "      <td>0.422706</td>\n",
       "      <td>0.422706</td>\n",
       "      <td>117258400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>27.38</td>\n",
       "      <td>27.38</td>\n",
       "      <td>27.25</td>\n",
       "      <td>27.25</td>\n",
       "      <td>785200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.402563</td>\n",
       "      <td>0.402563</td>\n",
       "      <td>0.400652</td>\n",
       "      <td>0.400652</td>\n",
       "      <td>43971200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>25.37</td>\n",
       "      <td>25.37</td>\n",
       "      <td>25.25</td>\n",
       "      <td>25.25</td>\n",
       "      <td>472000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373010</td>\n",
       "      <td>0.373010</td>\n",
       "      <td>0.371246</td>\n",
       "      <td>0.371246</td>\n",
       "      <td>26432000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close     Volume  Ex_Dividend  Split_Ratio  \\\n",
       "Date                                                                          \n",
       "1980-12-12  28.75  28.87  28.75  28.75  2093900.0          0.0          1.0   \n",
       "1980-12-15  27.38  27.38  27.25  27.25   785200.0          0.0          1.0   \n",
       "1980-12-16  25.37  25.37  25.25  25.25   472000.0          0.0          1.0   \n",
       "\n",
       "            Adj_Open  Adj_High   Adj_Low  Adj_Close   Adj_Volume  \n",
       "Date                                                              \n",
       "1980-12-12  0.422706  0.424470  0.422706   0.422706  117258400.0  \n",
       "1980-12-15  0.402563  0.402563  0.400652   0.400652   43971200.0  \n",
       "1980-12-16  0.373010  0.373010  0.371246   0.371246   26432000.0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the Everything Before July 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[:'2014-07-01'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex_Dividend</th>\n",
       "      <th>Split_Ratio</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Adj_Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-07-02</th>\n",
       "      <td>93.865</td>\n",
       "      <td>94.06</td>\n",
       "      <td>93.09</td>\n",
       "      <td>93.480</td>\n",
       "      <td>28465000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.348738</td>\n",
       "      <td>88.532278</td>\n",
       "      <td>87.619283</td>\n",
       "      <td>87.986364</td>\n",
       "      <td>28465000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-03</th>\n",
       "      <td>93.670</td>\n",
       "      <td>94.10</td>\n",
       "      <td>93.20</td>\n",
       "      <td>94.030</td>\n",
       "      <td>22891800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.165198</td>\n",
       "      <td>88.569928</td>\n",
       "      <td>87.722819</td>\n",
       "      <td>88.504041</td>\n",
       "      <td>22891800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-07</th>\n",
       "      <td>94.140</td>\n",
       "      <td>95.99</td>\n",
       "      <td>94.10</td>\n",
       "      <td>95.968</td>\n",
       "      <td>56468000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.607577</td>\n",
       "      <td>90.348856</td>\n",
       "      <td>88.569928</td>\n",
       "      <td>90.328149</td>\n",
       "      <td>56468000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open   High    Low   Close      Volume  Ex_Dividend  \\\n",
       "Date                                                                \n",
       "2014-07-02  93.865  94.06  93.09  93.480  28465000.0          0.0   \n",
       "2014-07-03  93.670  94.10  93.20  94.030  22891800.0          0.0   \n",
       "2014-07-07  94.140  95.99  94.10  95.968  56468000.0          0.0   \n",
       "\n",
       "            Split_Ratio   Adj_Open   Adj_High    Adj_Low  Adj_Close  \\\n",
       "Date                                                                  \n",
       "2014-07-02          1.0  88.348738  88.532278  87.619283  87.986364   \n",
       "2014-07-03          1.0  88.165198  88.569928  87.722819  88.504041   \n",
       "2014-07-07          1.0  88.607577  90.348856  88.569928  90.328149   \n",
       "\n",
       "            Adj_Volume  \n",
       "Date                    \n",
       "2014-07-02  28465000.0  \n",
       "2014-07-03  22891800.0  \n",
       "2014-07-07  56468000.0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Splitting the Data a Training and Testing Set\n",
    "\n",
    "## Creating a Function for the Training Set with Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_dates(df):\n",
    "    shifted_df = pd.DataFrame(df[:-1].values, index = df[1:].index, columns=df.columns)\n",
    "    return shifted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_and_shift_data(dataframe):\n",
    "    temp_df = dataframe.copy()\n",
    "    \n",
    "    short_SMA = temp_df.rolling(window=12).mean().copy()\n",
    "    mid_SMA = temp_df.rolling(window=26).mean().copy()\n",
    "    long_SMA = temp_df.rolling(window=85).mean().copy()\n",
    "\n",
    "    short_EMA = temp_df.ewm(span=12, adjust=False).mean().copy()\n",
    "    mid_EMA = temp_df.ewm(span=26, adjust=False).mean().copy()\n",
    "    long_EMA = temp_df.ewm(span=85, adjust=False).mean().copy()\n",
    "    \n",
    "    temp_df = pd.merge(temp_df, short_SMA, left_index=True, right_index=True, suffixes=['','_Short_SMA'])\n",
    "    temp_df = pd.merge(temp_df, mid_SMA, left_index=True, right_index=True, suffixes=['','_Mid_SMA'])\n",
    "    temp_df = pd.merge(temp_df, long_SMA, left_index=True, right_index=True, suffixes=['','_Long_SMA'])\n",
    "    \n",
    "    temp_df = pd.merge(temp_df, short_EMA, left_index=True, right_index=True, suffixes=['','_Short_EMA'])\n",
    "    temp_df = pd.merge(temp_df, mid_EMA, left_index=True, right_index=True, suffixes=['','_Mid_EMA'])\n",
    "    temp_df = pd.merge(temp_df, long_EMA, left_index=True, right_index=True, suffixes=['','_Long_EMA'])\n",
    "    \n",
    "    temp_df.dropna(inplace=True) \n",
    "    \n",
    "    temp_df = shift_dates(temp_df)\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_shift = lag_and_shift_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex_Dividend</th>\n",
       "      <th>Split_Ratio</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_Long_EMA</th>\n",
       "      <th>Close_Long_EMA</th>\n",
       "      <th>Volume_Long_EMA</th>\n",
       "      <th>Ex_Dividend_Long_EMA</th>\n",
       "      <th>Split_Ratio_Long_EMA</th>\n",
       "      <th>Adj_Open_Long_EMA</th>\n",
       "      <th>Adj_High_Long_EMA</th>\n",
       "      <th>Adj_Low_Long_EMA</th>\n",
       "      <th>Adj_Close_Long_EMA</th>\n",
       "      <th>Adj_Volume_Long_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-10-31</th>\n",
       "      <td>106.959</td>\n",
       "      <td>107.35</td>\n",
       "      <td>105.900</td>\n",
       "      <td>106.98</td>\n",
       "      <td>40654793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.174038</td>\n",
       "      <td>101.543891</td>\n",
       "      <td>100.172315</td>\n",
       "      <td>...</td>\n",
       "      <td>98.626302</td>\n",
       "      <td>99.449687</td>\n",
       "      <td>5.503428e+07</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.946729</td>\n",
       "      <td>94.716652</td>\n",
       "      <td>93.184824</td>\n",
       "      <td>93.963038</td>\n",
       "      <td>5.503428e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-03</th>\n",
       "      <td>108.010</td>\n",
       "      <td>108.04</td>\n",
       "      <td>107.210</td>\n",
       "      <td>108.00</td>\n",
       "      <td>44639285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.168194</td>\n",
       "      <td>102.196572</td>\n",
       "      <td>101.411463</td>\n",
       "      <td>...</td>\n",
       "      <td>98.825923</td>\n",
       "      <td>99.648531</td>\n",
       "      <td>5.479254e+07</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.137926</td>\n",
       "      <td>94.890604</td>\n",
       "      <td>93.376141</td>\n",
       "      <td>94.153636</td>\n",
       "      <td>5.479254e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-04</th>\n",
       "      <td>108.220</td>\n",
       "      <td>110.30</td>\n",
       "      <td>108.010</td>\n",
       "      <td>109.40</td>\n",
       "      <td>52282550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.366836</td>\n",
       "      <td>104.334338</td>\n",
       "      <td>102.168194</td>\n",
       "      <td>...</td>\n",
       "      <td>99.039506</td>\n",
       "      <td>99.875310</td>\n",
       "      <td>5.473417e+07</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.329296</td>\n",
       "      <td>95.110226</td>\n",
       "      <td>93.580607</td>\n",
       "      <td>94.370598</td>\n",
       "      <td>5.473417e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-05</th>\n",
       "      <td>109.360</td>\n",
       "      <td>109.49</td>\n",
       "      <td>107.720</td>\n",
       "      <td>108.60</td>\n",
       "      <td>41574365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.445178</td>\n",
       "      <td>103.568147</td>\n",
       "      <td>101.893879</td>\n",
       "      <td>...</td>\n",
       "      <td>99.241378</td>\n",
       "      <td>100.078209</td>\n",
       "      <td>5.442812e+07</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.541293</td>\n",
       "      <td>95.306922</td>\n",
       "      <td>93.773939</td>\n",
       "      <td>94.564917</td>\n",
       "      <td>5.442812e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-06</th>\n",
       "      <td>109.100</td>\n",
       "      <td>109.30</td>\n",
       "      <td>108.125</td>\n",
       "      <td>108.86</td>\n",
       "      <td>37435905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.199241</td>\n",
       "      <td>103.388423</td>\n",
       "      <td>102.276974</td>\n",
       "      <td>...</td>\n",
       "      <td>99.447974</td>\n",
       "      <td>100.282437</td>\n",
       "      <td>5.403296e+07</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.742641</td>\n",
       "      <td>95.494863</td>\n",
       "      <td>93.971684</td>\n",
       "      <td>94.760435</td>\n",
       "      <td>5.403296e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open    High      Low   Close      Volume  Ex_Dividend  \\\n",
       "Date                                                                    \n",
       "2014-10-31  106.959  107.35  105.900  106.98  40654793.0          0.0   \n",
       "2014-11-03  108.010  108.04  107.210  108.00  44639285.0          0.0   \n",
       "2014-11-04  108.220  110.30  108.010  109.40  52282550.0          0.0   \n",
       "2014-11-05  109.360  109.49  107.720  108.60  41574365.0          0.0   \n",
       "2014-11-06  109.100  109.30  108.125  108.86  37435905.0          0.0   \n",
       "\n",
       "            Split_Ratio    Adj_Open    Adj_High     Adj_Low  \\\n",
       "Date                                                          \n",
       "2014-10-31          1.0  101.174038  101.543891  100.172315   \n",
       "2014-11-03          1.0  102.168194  102.196572  101.411463   \n",
       "2014-11-04          1.0  102.366836  104.334338  102.168194   \n",
       "2014-11-05          1.0  103.445178  103.568147  101.893879   \n",
       "2014-11-06          1.0  103.199241  103.388423  102.276974   \n",
       "\n",
       "                   ...           Low_Long_EMA  Close_Long_EMA  \\\n",
       "Date               ...                                          \n",
       "2014-10-31         ...              98.626302       99.449687   \n",
       "2014-11-03         ...              98.825923       99.648531   \n",
       "2014-11-04         ...              99.039506       99.875310   \n",
       "2014-11-05         ...              99.241378      100.078209   \n",
       "2014-11-06         ...              99.447974      100.282437   \n",
       "\n",
       "            Volume_Long_EMA  Ex_Dividend_Long_EMA  Split_Ratio_Long_EMA  \\\n",
       "Date                                                                      \n",
       "2014-10-31     5.503428e+07              0.002727                   1.0   \n",
       "2014-11-03     5.479254e+07              0.002664                   1.0   \n",
       "2014-11-04     5.473417e+07              0.002602                   1.0   \n",
       "2014-11-05     5.442812e+07              0.002541                   1.0   \n",
       "2014-11-06     5.403296e+07              0.002482                   1.0   \n",
       "\n",
       "            Adj_Open_Long_EMA  Adj_High_Long_EMA  Adj_Low_Long_EMA  \\\n",
       "Date                                                                 \n",
       "2014-10-31          93.946729          94.716652         93.184824   \n",
       "2014-11-03          94.137926          94.890604         93.376141   \n",
       "2014-11-04          94.329296          95.110226         93.580607   \n",
       "2014-11-05          94.541293          95.306922         93.773939   \n",
       "2014-11-06          94.742641          95.494863         93.971684   \n",
       "\n",
       "            Adj_Close_Long_EMA  Adj_Volume_Long_EMA  \n",
       "Date                                                 \n",
       "2014-10-31           93.963038         5.503428e+07  \n",
       "2014-11-03           94.153636         5.479254e+07  \n",
       "2014-11-04           94.370598         5.473417e+07  \n",
       "2014-11-05           94.564917         5.442812e+07  \n",
       "2014-11-06           94.760435         5.403296e+07  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shift.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a Look at the Time-Shifted Data Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex_Dividend</th>\n",
       "      <th>Split_Ratio</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_Long_EMA</th>\n",
       "      <th>Close_Long_EMA</th>\n",
       "      <th>Volume_Long_EMA</th>\n",
       "      <th>Ex_Dividend_Long_EMA</th>\n",
       "      <th>Split_Ratio_Long_EMA</th>\n",
       "      <th>Adj_Open_Long_EMA</th>\n",
       "      <th>Adj_High_Long_EMA</th>\n",
       "      <th>Adj_Low_Long_EMA</th>\n",
       "      <th>Adj_Close_Long_EMA</th>\n",
       "      <th>Adj_Volume_Long_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>170.00</td>\n",
       "      <td>172.68</td>\n",
       "      <td>168.60</td>\n",
       "      <td>168.845</td>\n",
       "      <td>41051076.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.00</td>\n",
       "      <td>172.68</td>\n",
       "      <td>168.60</td>\n",
       "      <td>...</td>\n",
       "      <td>169.691723</td>\n",
       "      <td>171.097703</td>\n",
       "      <td>3.358258e+07</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.126419</td>\n",
       "      <td>172.657153</td>\n",
       "      <td>169.671634</td>\n",
       "      <td>171.077463</td>\n",
       "      <td>3.358258e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>168.39</td>\n",
       "      <td>169.92</td>\n",
       "      <td>164.94</td>\n",
       "      <td>164.940</td>\n",
       "      <td>40248954.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.39</td>\n",
       "      <td>169.92</td>\n",
       "      <td>164.94</td>\n",
       "      <td>...</td>\n",
       "      <td>169.581218</td>\n",
       "      <td>170.954500</td>\n",
       "      <td>3.373761e+07</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.062781</td>\n",
       "      <td>172.593499</td>\n",
       "      <td>169.561596</td>\n",
       "      <td>170.934731</td>\n",
       "      <td>3.373761e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>168.07</td>\n",
       "      <td>173.10</td>\n",
       "      <td>166.44</td>\n",
       "      <td>172.770</td>\n",
       "      <td>36272617.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.07</td>\n",
       "      <td>173.10</td>\n",
       "      <td>166.44</td>\n",
       "      <td>...</td>\n",
       "      <td>169.508166</td>\n",
       "      <td>170.996721</td>\n",
       "      <td>3.379657e+07</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.993182</td>\n",
       "      <td>172.605278</td>\n",
       "      <td>169.489000</td>\n",
       "      <td>170.977412</td>\n",
       "      <td>3.379657e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low    Close      Volume  Ex_Dividend  \\\n",
       "Date                                                                   \n",
       "2018-03-23  170.00  172.68  168.60  168.845  41051076.0          0.0   \n",
       "2018-03-26  168.39  169.92  164.94  164.940  40248954.0          0.0   \n",
       "2018-03-27  168.07  173.10  166.44  172.770  36272617.0          0.0   \n",
       "\n",
       "            Split_Ratio  Adj_Open  Adj_High  Adj_Low         ...           \\\n",
       "Date                                                         ...            \n",
       "2018-03-23          1.0    170.00    172.68   168.60         ...            \n",
       "2018-03-26          1.0    168.39    169.92   164.94         ...            \n",
       "2018-03-27          1.0    168.07    173.10   166.44         ...            \n",
       "\n",
       "            Low_Long_EMA  Close_Long_EMA  Volume_Long_EMA  \\\n",
       "Date                                                        \n",
       "2018-03-23    169.691723      171.097703     3.358258e+07   \n",
       "2018-03-26    169.581218      170.954500     3.373761e+07   \n",
       "2018-03-27    169.508166      170.996721     3.379657e+07   \n",
       "\n",
       "            Ex_Dividend_Long_EMA  Split_Ratio_Long_EMA  Adj_Open_Long_EMA  \\\n",
       "Date                                                                        \n",
       "2018-03-23              0.000518                   1.0         171.126419   \n",
       "2018-03-26              0.000506                   1.0         171.062781   \n",
       "2018-03-27              0.000494                   1.0         170.993182   \n",
       "\n",
       "            Adj_High_Long_EMA  Adj_Low_Long_EMA  Adj_Close_Long_EMA  \\\n",
       "Date                                                                  \n",
       "2018-03-23         172.657153        169.671634          171.077463   \n",
       "2018-03-26         172.593499        169.561596          170.934731   \n",
       "2018-03-27         172.605278        169.489000          170.977412   \n",
       "\n",
       "            Adj_Volume_Long_EMA  \n",
       "Date                             \n",
       "2018-03-23         3.358258e+07  \n",
       "2018-03-26         3.373761e+07  \n",
       "2018-03-27         3.379657e+07  \n",
       "\n",
       "[3 rows x 84 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shift.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shift['2014-07-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Everything Before July 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shift.drop(df_shift[:'2014-07-01'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shift.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(dataframe):\n",
    "    temp_df = dataframe.copy()\n",
    "    X_test = temp_df['2016-07-02':'2017-03-27']\n",
    "    temp_df.drop(temp_df['2016-03-02':'2016-12-01'].index, inplace=True)\n",
    "    X_train = temp_df\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = data_split(df_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Function for a Training a Testing Set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_split(dataframe):\n",
    "#     temp_df = dataframe.copy()\n",
    "#     X_test = temp_df['2016-07-02':'2017-03-27']\n",
    "#     temp_df.drop(temp_df['2016-07-02':'2017-03-27'].index, inplace=True)\n",
    "#     X_train = temp_df\n",
    "#     return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = data_split(df_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex_Dividend</th>\n",
       "      <th>Split_Ratio</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_Long_EMA</th>\n",
       "      <th>Close_Long_EMA</th>\n",
       "      <th>Volume_Long_EMA</th>\n",
       "      <th>Ex_Dividend_Long_EMA</th>\n",
       "      <th>Split_Ratio_Long_EMA</th>\n",
       "      <th>Adj_Open_Long_EMA</th>\n",
       "      <th>Adj_High_Long_EMA</th>\n",
       "      <th>Adj_Low_Long_EMA</th>\n",
       "      <th>Adj_Close_Long_EMA</th>\n",
       "      <th>Adj_Volume_Long_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-10-31</th>\n",
       "      <td>106.959</td>\n",
       "      <td>107.35</td>\n",
       "      <td>105.90</td>\n",
       "      <td>106.98</td>\n",
       "      <td>40654793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.174038</td>\n",
       "      <td>101.543891</td>\n",
       "      <td>100.172315</td>\n",
       "      <td>...</td>\n",
       "      <td>98.626302</td>\n",
       "      <td>99.449687</td>\n",
       "      <td>5.503428e+07</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.946729</td>\n",
       "      <td>94.716652</td>\n",
       "      <td>93.184824</td>\n",
       "      <td>93.963038</td>\n",
       "      <td>5.503428e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-03</th>\n",
       "      <td>108.010</td>\n",
       "      <td>108.04</td>\n",
       "      <td>107.21</td>\n",
       "      <td>108.00</td>\n",
       "      <td>44639285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.168194</td>\n",
       "      <td>102.196572</td>\n",
       "      <td>101.411463</td>\n",
       "      <td>...</td>\n",
       "      <td>98.825923</td>\n",
       "      <td>99.648531</td>\n",
       "      <td>5.479254e+07</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.137926</td>\n",
       "      <td>94.890604</td>\n",
       "      <td>93.376141</td>\n",
       "      <td>94.153636</td>\n",
       "      <td>5.479254e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-04</th>\n",
       "      <td>108.220</td>\n",
       "      <td>110.30</td>\n",
       "      <td>108.01</td>\n",
       "      <td>109.40</td>\n",
       "      <td>52282550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.366836</td>\n",
       "      <td>104.334338</td>\n",
       "      <td>102.168194</td>\n",
       "      <td>...</td>\n",
       "      <td>99.039506</td>\n",
       "      <td>99.875310</td>\n",
       "      <td>5.473417e+07</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.329296</td>\n",
       "      <td>95.110226</td>\n",
       "      <td>93.580607</td>\n",
       "      <td>94.370598</td>\n",
       "      <td>5.473417e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open    High     Low   Close      Volume  Ex_Dividend  \\\n",
       "Date                                                                   \n",
       "2014-10-31  106.959  107.35  105.90  106.98  40654793.0          0.0   \n",
       "2014-11-03  108.010  108.04  107.21  108.00  44639285.0          0.0   \n",
       "2014-11-04  108.220  110.30  108.01  109.40  52282550.0          0.0   \n",
       "\n",
       "            Split_Ratio    Adj_Open    Adj_High     Adj_Low  \\\n",
       "Date                                                          \n",
       "2014-10-31          1.0  101.174038  101.543891  100.172315   \n",
       "2014-11-03          1.0  102.168194  102.196572  101.411463   \n",
       "2014-11-04          1.0  102.366836  104.334338  102.168194   \n",
       "\n",
       "                   ...           Low_Long_EMA  Close_Long_EMA  \\\n",
       "Date               ...                                          \n",
       "2014-10-31         ...              98.626302       99.449687   \n",
       "2014-11-03         ...              98.825923       99.648531   \n",
       "2014-11-04         ...              99.039506       99.875310   \n",
       "\n",
       "            Volume_Long_EMA  Ex_Dividend_Long_EMA  Split_Ratio_Long_EMA  \\\n",
       "Date                                                                      \n",
       "2014-10-31     5.503428e+07              0.002727                   1.0   \n",
       "2014-11-03     5.479254e+07              0.002664                   1.0   \n",
       "2014-11-04     5.473417e+07              0.002602                   1.0   \n",
       "\n",
       "            Adj_Open_Long_EMA  Adj_High_Long_EMA  Adj_Low_Long_EMA  \\\n",
       "Date                                                                 \n",
       "2014-10-31          93.946729          94.716652         93.184824   \n",
       "2014-11-03          94.137926          94.890604         93.376141   \n",
       "2014-11-04          94.329296          95.110226         93.580607   \n",
       "\n",
       "            Adj_Close_Long_EMA  Adj_Volume_Long_EMA  \n",
       "Date                                                 \n",
       "2014-10-31           93.963038         5.503428e+07  \n",
       "2014-11-03           94.153636         5.479254e+07  \n",
       "2014-11-04           94.370598         5.473417e+07  \n",
       "\n",
       "[3 rows x 84 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex_Dividend</th>\n",
       "      <th>Split_Ratio</th>\n",
       "      <th>Adj_Open</th>\n",
       "      <th>Adj_High</th>\n",
       "      <th>Adj_Low</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_Long_EMA</th>\n",
       "      <th>Close_Long_EMA</th>\n",
       "      <th>Volume_Long_EMA</th>\n",
       "      <th>Ex_Dividend_Long_EMA</th>\n",
       "      <th>Split_Ratio_Long_EMA</th>\n",
       "      <th>Adj_Open_Long_EMA</th>\n",
       "      <th>Adj_High_Long_EMA</th>\n",
       "      <th>Adj_Low_Long_EMA</th>\n",
       "      <th>Adj_Close_Long_EMA</th>\n",
       "      <th>Adj_Volume_Long_EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>95.49</td>\n",
       "      <td>96.465</td>\n",
       "      <td>95.33</td>\n",
       "      <td>95.89</td>\n",
       "      <td>26026540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.321192</td>\n",
       "      <td>94.274047</td>\n",
       "      <td>93.164826</td>\n",
       "      <td>...</td>\n",
       "      <td>98.298623</td>\n",
       "      <td>99.153689</td>\n",
       "      <td>3.984747e+07</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.547814</td>\n",
       "      <td>97.431902</td>\n",
       "      <td>95.771692</td>\n",
       "      <td>96.604325</td>\n",
       "      <td>3.984747e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-06</th>\n",
       "      <td>95.39</td>\n",
       "      <td>95.400</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.99</td>\n",
       "      <td>27705210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.223463</td>\n",
       "      <td>93.233236</td>\n",
       "      <td>92.314586</td>\n",
       "      <td>...</td>\n",
       "      <td>98.209353</td>\n",
       "      <td>99.056859</td>\n",
       "      <td>3.956509e+07</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.470504</td>\n",
       "      <td>97.334258</td>\n",
       "      <td>95.691294</td>\n",
       "      <td>96.516610</td>\n",
       "      <td>3.956509e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-07</th>\n",
       "      <td>94.60</td>\n",
       "      <td>95.660</td>\n",
       "      <td>94.37</td>\n",
       "      <td>95.53</td>\n",
       "      <td>30949090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.451406</td>\n",
       "      <td>93.487331</td>\n",
       "      <td>92.226630</td>\n",
       "      <td>...</td>\n",
       "      <td>98.120066</td>\n",
       "      <td>98.974839</td>\n",
       "      <td>3.936472e+07</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.377036</td>\n",
       "      <td>97.244795</td>\n",
       "      <td>95.610720</td>\n",
       "      <td>96.443207</td>\n",
       "      <td>3.936472e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open    High    Low  Close      Volume  Ex_Dividend  Split_Ratio  \\\n",
       "Date                                                                            \n",
       "2016-07-05  95.49  96.465  95.33  95.89  26026540.0          0.0          1.0   \n",
       "2016-07-06  95.39  95.400  94.46  94.99  27705210.0          0.0          1.0   \n",
       "2016-07-07  94.60  95.660  94.37  95.53  30949090.0          0.0          1.0   \n",
       "\n",
       "             Adj_Open   Adj_High    Adj_Low         ...           \\\n",
       "Date                                                ...            \n",
       "2016-07-05  93.321192  94.274047  93.164826         ...            \n",
       "2016-07-06  93.223463  93.233236  92.314586         ...            \n",
       "2016-07-07  92.451406  93.487331  92.226630         ...            \n",
       "\n",
       "            Low_Long_EMA  Close_Long_EMA  Volume_Long_EMA  \\\n",
       "Date                                                        \n",
       "2016-07-05     98.298623       99.153689     3.984747e+07   \n",
       "2016-07-06     98.209353       99.056859     3.956509e+07   \n",
       "2016-07-07     98.120066       98.974839     3.936472e+07   \n",
       "\n",
       "            Ex_Dividend_Long_EMA  Split_Ratio_Long_EMA  Adj_Open_Long_EMA  \\\n",
       "Date                                                                        \n",
       "2016-07-05              0.006571                   1.0          96.547814   \n",
       "2016-07-06              0.006418                   1.0          96.470504   \n",
       "2016-07-07              0.006269                   1.0          96.377036   \n",
       "\n",
       "            Adj_High_Long_EMA  Adj_Low_Long_EMA  Adj_Close_Long_EMA  \\\n",
       "Date                                                                  \n",
       "2016-07-05          97.431902         95.771692           96.604325   \n",
       "2016-07-06          97.334258         95.691294           96.516610   \n",
       "2016-07-07          97.244795         95.610720           96.443207   \n",
       "\n",
       "            Adj_Volume_Long_EMA  \n",
       "Date                             \n",
       "2016-07-05         3.984747e+07  \n",
       "2016-07-06         3.956509e+07  \n",
       "2016-07-07         3.936472e+07  \n",
       "\n",
       "[3 rows x 84 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Normalizing the Data with a MinMaxScaler\n",
    "\n",
    "## Instantiating the Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = scaler.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sc = scaler.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the y Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 84)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[X_train.index[0]:X_train.index[-1]].Close.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the y Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df[X_test.index[0]:X_test.index[-1]].Close.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Random Forest Regression Model\n",
    "\n",
    "## Setting up the Random Forest (RF) Regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, max_depth=15, \n",
    "                           min_samples_leaf=3, bootstrap=False, \n",
    "                           n_jobs=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(939, 12)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 84)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Scaled Data with the RF Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105839c00, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/adamd.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105839c00, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/adamd.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rf.fit(X_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 9, 18, 7, 27, 565165, tzinfo=tzutc()), 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'session': 'd9c573d2d0594f4d86b299a1aad307eb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd9c573d2d0594f4d86b299a1aad307eb']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'rf.fit(X_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 9, 18, 7, 27, 565165, tzinfo=tzutc()), 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'session': 'd9c573d2d0594f4d86b299a1aad307eb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd9c573d2d0594f4d86b299a1aad307eb'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rf.fit(X_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 9, 18, 7, 27, 565165, tzinfo=tzutc()), 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'session': 'd9c573d2d0594f4d86b299a1aad307eb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='rf.fit(X_train_sc, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'rf.fit(X_train_sc, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('rf.fit(X_train_sc, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('rf.fit(X_train_sc, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rf.fit(X_train_sc, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'rf.fit(X_train_sc, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rf.fit(X_train_sc, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-140-e3af0ef1b6ae>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 115537ba8, execution_...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x115500930, file \"<ipython-input-140-e3af0ef1b6ae>\", line 1>\n        result = <ExecutionResult object at 115537ba8, execution_...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x115500930, file \"<ipython-input-140-e3af0ef1b6ae>\", line 1>, result=<ExecutionResult object at 115537ba8, execution_...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x115500930, file \"<ipython-input-140-e3af0ef1b6ae>\", line 1>\n        self.user_global_ns = {'In': ['', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'import pandas as pd\\nimport numpy as np\\nimport ma...onfig\\', \"InlineBackend.figure_format = \\'retina\\'\")', \"company_name = 'Apple'\", 'def data_reader(company_name):\\n    company_name=...index(inplace=True, ascending=True)\\n    return df', \"df = data_reader('Apple')\", 'df.head(3)', 'def shift_dates(df):\\n    shifted_df = pd.DataFra....index, columns=df.columns)\\n    return shifted_df', 'def lag_and_shift_data(dataframe):\\n    temp_df =...emp_df = shift_dates(temp_df)\\n\\n    return temp_df', 'df_shift = lag_and_shift_data(df)', 'df_shift.head()', 'df_shift.tail(3)', \"# df_shift['2014-07-01':]\", \"df_shift.drop(df_shift[:'2014-07-01'].index, inplace=True)\", 'df_shift.head(3)', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'def data_split(dataframe):\\n    temp_df = datafra...=True)\\n    train = temp_df\\n    return train, test', 'train, test = data_split(df_shift)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {7:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 11:              Open   High    Low  Close    Volume...263         2.086528e+07  \n\n[5 rows x 84 columns], 12:               Open    High     Low    Close     ...-27         3.379657e+07  \n\n[3 rows x 84 columns], 15:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 20:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 21:              Open    High    Low  Close      Vol...-07         3.936497e+07  \n\n[3 rows x 84 columns], 22:              Open   High    Low  Close     Volum...536  0.393300  0.391536   0.391536   18362400.0  , 27:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 28:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 30:               Open   High    Low   Close      Vo...2014-07-03  22891800.0  \n2014-07-07  56468000.0  , ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TimeSeriesSplit': <class 'sklearn.model_selection._split.TimeSeriesSplit'>, 'X_test':                Open      High       Low    Close...9         2.823258e+07  \n\n[184 rows x 84 columns], 'X_test_sc': array([[-0.94723899, -0.9558427 , -0.92449836, .... -0.14502245,\n        -0.15189614, -0.80361455]]), 'X_train':                Open     High       Low    Close ...2         3.379657e+07  \n\n[662 rows x 84 columns], ...}\n        self.user_ns = {'In': ['', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'import pandas as pd\\nimport numpy as np\\nimport ma...onfig\\', \"InlineBackend.figure_format = \\'retina\\'\")', \"company_name = 'Apple'\", 'def data_reader(company_name):\\n    company_name=...index(inplace=True, ascending=True)\\n    return df', \"df = data_reader('Apple')\", 'df.head(3)', 'def shift_dates(df):\\n    shifted_df = pd.DataFra....index, columns=df.columns)\\n    return shifted_df', 'def lag_and_shift_data(dataframe):\\n    temp_df =...emp_df = shift_dates(temp_df)\\n\\n    return temp_df', 'df_shift = lag_and_shift_data(df)', 'df_shift.head()', 'df_shift.tail(3)', \"# df_shift['2014-07-01':]\", \"df_shift.drop(df_shift[:'2014-07-01'].index, inplace=True)\", 'df_shift.head(3)', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'def data_split(dataframe):\\n    temp_df = datafra...=True)\\n    train = temp_df\\n    return train, test', 'train, test = data_split(df_shift)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {7:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 11:              Open   High    Low  Close    Volume...263         2.086528e+07  \n\n[5 rows x 84 columns], 12:               Open    High     Low    Close     ...-27         3.379657e+07  \n\n[3 rows x 84 columns], 15:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 20:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 21:              Open    High    Low  Close      Vol...-07         3.936497e+07  \n\n[3 rows x 84 columns], 22:              Open   High    Low  Close     Volum...536  0.393300  0.391536   0.391536   18362400.0  , 27:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 28:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 30:               Open   High    Low   Close      Vo...2014-07-03  22891800.0  \n2014-07-07  56468000.0  , ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TimeSeriesSplit': <class 'sklearn.model_selection._split.TimeSeriesSplit'>, 'X_test':                Open      High       Low    Close...9         2.823258e+07  \n\n[184 rows x 84 columns], 'X_test_sc': array([[-0.94723899, -0.9558427 , -0.92449836, .... -0.14502245,\n        -0.15189614, -0.80361455]]), 'X_train':                Open     High       Low    Close ...2         3.379657e+07  \n\n[662 rows x 84 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/Users/adamdelreal/dsi/projects/capstone/stocks/<ipython-input-140-e3af0ef1b6ae> in <module>()\n----> 1 rf.fit(X_train_sc, y_train)\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 99\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jul  9 11:07:27 2018\nPID: 2737Python 3.6.5: /Users/adamdelreal/anaconda3/envs/tensorflow/bin/python\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), None, 0, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), forest=RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n    121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    122     else:\n--> 123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1608637542, splitter='best')>\n        X = array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32)\n        y = array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]])\n        sample_weight = None\n    124 \n    125     return tree\n    126 \n    127 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, check_input=False, X_idx_sorted=None)\n    231 \n    232         self.max_features_ = max_features\n    233 \n    234         if len(y) != n_samples:\n    235             raise ValueError(\"Number of labels=%d does not match \"\n--> 236                              \"number of samples=%d\" % (len(y), n_samples))\n        y = array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]])\n        n_samples = 662\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n\nValueError: Number of labels=854 does not match number of samples=662\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    235\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0;32m--> 236\u001b[0;31m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=854 does not match number of samples=662",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Jul  9 11:07:27 2018\nPID: 2737Python 3.6.5: /Users/adamdelreal/anaconda3/envs/tensorflow/bin/python\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), None, 0, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), forest=RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n    121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    122     else:\n--> 123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1608637542, splitter='best')>\n        X = array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32)\n        y = array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]])\n        sample_weight = None\n    124 \n    125     return tree\n    126 \n    127 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, check_input=False, X_idx_sorted=None)\n    231 \n    232         self.max_features_ = max_features\n    233 \n    234         if len(y) != n_samples:\n    235             raise ValueError(\"Number of labels=%d does not match \"\n--> 236                              \"number of samples=%d\" % (len(y), n_samples))\n        y = array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]])\n        n_samples = 662\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n\nValueError: Number of labels=854 does not match number of samples=662\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-e3af0ef1b6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x105839c00, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/adamd.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105839c00, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/adamd.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rf.fit(X_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 9, 18, 7, 27, 565165, tzinfo=tzutc()), 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'session': 'd9c573d2d0594f4d86b299a1aad307eb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd9c573d2d0594f4d86b299a1aad307eb']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'rf.fit(X_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 9, 18, 7, 27, 565165, tzinfo=tzutc()), 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'session': 'd9c573d2d0594f4d86b299a1aad307eb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd9c573d2d0594f4d86b299a1aad307eb'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'rf.fit(X_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 7, 9, 18, 7, 27, 565165, tzinfo=tzutc()), 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'session': 'd9c573d2d0594f4d86b299a1aad307eb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b9b51b5faa2e4a2e82239f61696f3a36', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='rf.fit(X_train_sc, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'rf.fit(X_train_sc, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('rf.fit(X_train_sc, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('rf.fit(X_train_sc, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rf.fit(X_train_sc, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'rf.fit(X_train_sc, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='rf.fit(X_train_sc, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-140-e3af0ef1b6ae>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 115537ba8, execution_...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x115500930, file \"<ipython-input-140-e3af0ef1b6ae>\", line 1>\n        result = <ExecutionResult object at 115537ba8, execution_...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x115500930, file \"<ipython-input-140-e3af0ef1b6ae>\", line 1>, result=<ExecutionResult object at 115537ba8, execution_...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x115500930, file \"<ipython-input-140-e3af0ef1b6ae>\", line 1>\n        self.user_global_ns = {'In': ['', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'import pandas as pd\\nimport numpy as np\\nimport ma...onfig\\', \"InlineBackend.figure_format = \\'retina\\'\")', \"company_name = 'Apple'\", 'def data_reader(company_name):\\n    company_name=...index(inplace=True, ascending=True)\\n    return df', \"df = data_reader('Apple')\", 'df.head(3)', 'def shift_dates(df):\\n    shifted_df = pd.DataFra....index, columns=df.columns)\\n    return shifted_df', 'def lag_and_shift_data(dataframe):\\n    temp_df =...emp_df = shift_dates(temp_df)\\n\\n    return temp_df', 'df_shift = lag_and_shift_data(df)', 'df_shift.head()', 'df_shift.tail(3)', \"# df_shift['2014-07-01':]\", \"df_shift.drop(df_shift[:'2014-07-01'].index, inplace=True)\", 'df_shift.head(3)', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'def data_split(dataframe):\\n    temp_df = datafra...=True)\\n    train = temp_df\\n    return train, test', 'train, test = data_split(df_shift)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {7:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 11:              Open   High    Low  Close    Volume...263         2.086528e+07  \n\n[5 rows x 84 columns], 12:               Open    High     Low    Close     ...-27         3.379657e+07  \n\n[3 rows x 84 columns], 15:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 20:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 21:              Open    High    Low  Close      Vol...-07         3.936497e+07  \n\n[3 rows x 84 columns], 22:              Open   High    Low  Close     Volum...536  0.393300  0.391536   0.391536   18362400.0  , 27:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 28:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 30:               Open   High    Low   Close      Vo...2014-07-03  22891800.0  \n2014-07-07  56468000.0  , ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TimeSeriesSplit': <class 'sklearn.model_selection._split.TimeSeriesSplit'>, 'X_test':                Open      High       Low    Close...9         2.823258e+07  \n\n[184 rows x 84 columns], 'X_test_sc': array([[-0.94723899, -0.9558427 , -0.92449836, .... -0.14502245,\n        -0.15189614, -0.80361455]]), 'X_train':                Open     High       Low    Close ...2         3.379657e+07  \n\n[662 rows x 84 columns], ...}\n        self.user_ns = {'In': ['', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'import pandas as pd\\nimport numpy as np\\nimport ma...onfig\\', \"InlineBackend.figure_format = \\'retina\\'\")', \"company_name = 'Apple'\", 'def data_reader(company_name):\\n    company_name=...index(inplace=True, ascending=True)\\n    return df', \"df = data_reader('Apple')\", 'df.head(3)', 'def shift_dates(df):\\n    shifted_df = pd.DataFra....index, columns=df.columns)\\n    return shifted_df', 'def lag_and_shift_data(dataframe):\\n    temp_df =...emp_df = shift_dates(temp_df)\\n\\n    return temp_df', 'df_shift = lag_and_shift_data(df)', 'df_shift.head()', 'df_shift.tail(3)', \"# df_shift['2014-07-01':]\", \"df_shift.drop(df_shift[:'2014-07-01'].index, inplace=True)\", 'df_shift.head(3)', 'def data_split(dataframe):\\n    temp_df = datafra...e)\\n    train = temp_df\\n    return X_train, X_test', 'train, test = data_split(df_shift)', 'def data_split(dataframe):\\n    temp_df = datafra...=True)\\n    train = temp_df\\n    return train, test', 'train, test = data_split(df_shift)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {7:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 11:              Open   High    Low  Close    Volume...263         2.086528e+07  \n\n[5 rows x 84 columns], 12:               Open    High     Low    Close     ...-27         3.379657e+07  \n\n[3 rows x 84 columns], 15:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 20:               Open   High    Low  Close      Vol...-07         6.474376e+07  \n\n[3 rows x 84 columns], 21:              Open    High    Low  Close      Vol...-07         3.936497e+07  \n\n[3 rows x 84 columns], 22:              Open   High    Low  Close     Volum...536  0.393300  0.391536   0.391536   18362400.0  , 27:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 28:              Open   High    Low  Close     Volum...010  0.373010  0.371246   0.371246   26432000.0  , 30:               Open   High    Low   Close      Vo...2014-07-03  22891800.0  \n2014-07-07  56468000.0  , ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'TimeSeriesSplit': <class 'sklearn.model_selection._split.TimeSeriesSplit'>, 'X_test':                Open      High       Low    Close...9         2.823258e+07  \n\n[184 rows x 84 columns], 'X_test_sc': array([[-0.94723899, -0.9558427 , -0.92449836, .... -0.14502245,\n        -0.15189614, -0.80361455]]), 'X_train':                Open     High       Low    Close ...2         3.379657e+07  \n\n[662 rows x 84 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/Users/adamdelreal/dsi/projects/capstone/stocks/<ipython-input-140-e3af0ef1b6ae> in <module>()\n----> 1 rf.fit(X_train_sc, y_train)\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None)\n    323             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    324                              backend=\"threading\")(\n    325                 delayed(_parallel_build_trees)(\n    326                     t, self, X, y, sample_weight, i, len(trees),\n    327                     verbose=self.verbose, class_weight=self.class_weight)\n--> 328                 for i, t in enumerate(trees))\n        i = 99\n    329 \n    330             # Collect newly grown trees\n    331             self.estimators_.extend(trees)\n    332 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Jul  9 11:07:27 2018\nPID: 2737Python 3.6.5: /Users/adamdelreal/anaconda3/envs/tensorflow/bin/python\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), None, 0, 100), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), None, 0, 100)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), forest=RandomForestRegressor(bootstrap=False, criterion...se, random_state=42, verbose=0, warm_start=False), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, tree_idx=0, n_trees=100, verbose=0, class_weight=None)\n    118         elif class_weight == 'balanced_subsample':\n    119             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    120 \n    121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n    122     else:\n--> 123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...False, random_state=1608637542, splitter='best')>\n        X = array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32)\n        y = array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]])\n        sample_weight = None\n    124 \n    125     return tree\n    126 \n    127 \n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, check_input=False, X_idx_sorted=None)\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/Users/adamdelreal/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...=False, random_state=1608637542, splitter='best'), X=array([[-0.69083387, -0.71123594, -0.684843  , ....        0.9960293 , -0.4830785 ]], dtype=float32), y=array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]]), sample_weight=None, check_input=False, X_idx_sorted=None)\n    231 \n    232         self.max_features_ = max_features\n    233 \n    234         if len(y) != n_samples:\n    235             raise ValueError(\"Number of labels=%d does not match \"\n--> 236                              \"number of samples=%d\" % (len(y), n_samples))\n        y = array([[108.    ],\n       [109.4   ],\n       [10...164.94  ],\n       [172.77  ],\n       [168.34  ]])\n        n_samples = 662\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n\nValueError: Number of labels=854 does not match number of samples=662\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring on the Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988511480564479"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring on the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.6526599373079107"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Average Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154.62082337662338"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182.12251210445518"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test_sc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011904761904761902"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef_weights = pd.DataFrame(rf.coef_, index=X_train.columns, columns=['weight'])\n",
    "# coef_weights.sort_values('weight').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Decomposing Signal Components with Principal Component Analysis (PCA):\n",
    "\n",
    "### Instantiating the PCA Decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Transforming the Scaled Training Set with PCA Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Scaled Test Set with PCA Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the PCA Weighted Training Data on a Random Forest Regressor Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=15,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=3, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the PCA Weighted Training Data on a Random Forest Regressor Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8824991349411133"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the PCA Weighted Test Data on a Random Forest Regressor Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Average Prediction Value of the PCA Weighted Training Data on a Random Forest Regressor Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.05874912845564"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test_pca).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Grid Searching a Random Forest Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('rf', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "\n",
    "n_estimators = [x for x in range(8, 14, 2)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [x for x in range(1, 3)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [x for x in range(1, 3)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'rf__n_estimators': n_estimators,\n",
    "           'rf__max_features': max_features,\n",
    "           'rf__max_depth': max_depth,\n",
    "           'rf__min_samples_split': min_samples_split,\n",
    "           'rf__min_samples_leaf': min_samples_leaf,\n",
    "           'rf__bootstrap': bootstrap}\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearching the Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search = GridSearchCV(pipe, params, n_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Scaled Data with the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_search.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, rf_search.predict(X_test_sc))\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_weights = pd.DataFrame(rf_search.coef_, index=X_train.columns, columns=['weight'])\n",
    "coef_weights.sort_values('weight').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `'rf__n_estimators': [40, 55, 70, 85, 100],` => `n_estimators=10, `\n",
    "\n",
    "\n",
    "- `'rf__max_features': ['auto', 'sqrt'],` => `max_features='auto',`\n",
    "\n",
    "\n",
    "- `'rf__max_depth': [2, 80, None],` => -`max_depth=None,`\n",
    "\n",
    "\n",
    "- `'rf__min_samples_split': [2, 5, 10],` => `min_samples_split=2,`\n",
    "\n",
    "\n",
    "- `'rf__min_samples_leaf': [1, 2, 4],` => `min_samples_leaf=1,`\n",
    "\n",
    "\n",
    "- `'rf__bootstrap': [True, False]` => `bootstrap=True,`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## GridSearching a Random Forest with PCA Decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_w = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators_w = [x for x in range(8, 14, 2)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features_w = ['auto', 'log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth_w = [x for x in range(1, 3)]\n",
    "max_depth_w.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split_w = [x for x in range(1, 5)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf_w = [x for x in range(1, 3)]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap_w = [True, False]\n",
    "\n",
    "# pca_n_components= [x for x in range(2, 24, 4)]\n",
    "\n",
    "# pca_svd_solver = ['auto', 'full', 'arpack', 'randomized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Parameters with PCA Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_w = {'rf__n_estimators': n_estimators_w,\n",
    "          'rf__max_features': max_features_w,\n",
    "          'rf__max_depth': max_depth_w,\n",
    "          'rf__min_samples_split': min_samples_split_w,\n",
    "          'rf__min_samples_leaf': min_samples_leaf_w,\n",
    "          'rf__bootstrap': bootstrap_w}\n",
    "print(params_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearching the Parameters with PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe_w, params_w, n_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Scaled Data with a Weighted Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, grid.predict(X_test_sc))\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
